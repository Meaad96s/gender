{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "#import face_alignment\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from numpy import ones, zeros, array\n",
    "#from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA as PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readimages():\n",
    "    img=cv2.imread('C:\\\\Users\\\\MeaadAlrshoud\\\\Documents\\\\GitHub\\\\gender\\\\Female_Dataset\\\\29a.jpg')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertygrey(img):\n",
    "    grey=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    mat=np(arraynp.float32(img)) / 255.0\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization (img):\n",
    "    normed= cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haar(img):\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    # Detect faces in the image\n",
    "    f_haar= face_cascade.detectMultiScale(\n",
    "    img,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    return f_haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Alignment\n",
    "#def face_alignment(l1,l2):\n",
    "#    fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False)\n",
    "#    input = io.imread('../test/assets/aflw-test.jpg')\n",
    "#preds = fa.get_landmarks(m_haar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def spatial-scale():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation(l1, l2):\n",
    "    # ones= [1 for img in l1]\n",
    "    label1 = ones((len(l1), 1))\n",
    "    label2= zeros((len(l2), 1))\n",
    "    #zeros=[0 for img in l2]\n",
    "    # print(a)\n",
    "    np.append(l1,label1)\n",
    "    # l1.append(a)\n",
    "    np.append(l2,label2,axis=1)\n",
    "    return l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(l1):\n",
    "    winSize = (64, 64)\n",
    "    blockSize = (16, 16)\n",
    "    blockStride = (8, 8)\n",
    "    cellSize = (8, 8)\n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = 4.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 2.0000000000000001e-01\n",
    "    gammaCorrection = 0\n",
    "    nlevels = 64\n",
    "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins, derivAperture, winSigma,\n",
    "                            histogramNormType, L2HysThreshold, gammaCorrection, nlevels)\n",
    "    # compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
    "    winStride = (8, 8)\n",
    "    padding = (8, 8)\n",
    "    locations = ((10, 20),)\n",
    "    f_hog = hog.compute(l1, winStride, padding, locations)\n",
    "    # Rescale histogram for better display\n",
    "    # hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    return f_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr_pca(x_train):\n",
    "    # X_std = StandardScaler().fit_transform(X)\n",
    "    # mean_vec = np.mean(X_std, axis=0)\n",
    "    # cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "    # print('Covariance matrix \\n%s' %cov_mat)\n",
    "    # Y = sklearn_pca.fit_transform(X_std)\n",
    "    # find the principal components\n",
    "    N_COMPONENTS = 2\n",
    "    pca = PCA(n_components=N_COMPONENTS, random_state=0, svd_solver='randomized')\n",
    "    X_train_pca = pca.fit_transform(x_train)\n",
    "    # X_test_pca = pca.transform(X_test)\n",
    "    '''pcaclf = clf.fit(X_train_pca, y_train)\n",
    "    print(\"pca test score\", pcaclf.score(X_test_pca, y_test))\n",
    "    print(\"pca train score\", pcaclf.score(X_train_pca, y_train))'''\n",
    "    # X_r = pca.fit(X).transform(X)\n",
    "    # Percentage of variance explained for each components\n",
    "    print('explained variance ratio (first two components): %s' % str(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',readimages()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
