{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for img in f_grey:\\n    # Output img with window name as 'image' \\n    cv2.imshow('image',img)\\n    # Maintain output window utill \\n    # user presses a key \\n    cv2.waitKey(0)\\n    # Destroying present windows on screen \\n    cv2.destroyAllWindows()\\n    \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "# Read RGB image\n",
    "females = [cv2.imread(file) for file in glob.glob('C:\\\\Users\\\\MeaadAlrshoud\\\\Documents\\\\GitHub\\\\Gender-Classification\\\\Female_Dataset\\\\*.jpg')]\n",
    "males = [cv2.imread(file) for file in glob.glob('C:\\\\Users\\\\MeaadAlrshoud\\\\Documents\\\\GitHub\\\\Gender-Classification\\\\Male_Dataset\\\\*.jpg')]\n",
    "\n",
    "#convert to greyscale\n",
    "f_grey= [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in females]\n",
    "m_grey=[cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in males]\n",
    "count=0\n",
    "# print the images\n",
    "'''for img in f_grey:\n",
    "    # Output img with window name as 'image' \n",
    "    cv2.imshow('image',img)\n",
    "    # Maintain output window utill \n",
    "    # user presses a key \n",
    "    cv2.waitKey(0)\n",
    "    # Destroying present windows on screen \n",
    "    cv2.destroyAllWindows()\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 23,  83, 221, 221]], dtype=int32),\n",
       " array([[ 10,  85, 245, 245]], dtype=int32),\n",
       " array([[ 22,  87, 219, 219]], dtype=int32),\n",
       " array([[ 20,  83, 229, 229]], dtype=int32),\n",
       " array([[ 22,  84, 227, 227]], dtype=int32),\n",
       " array([[ 34,  99, 203, 203]], dtype=int32),\n",
       " array([[ 24,  87, 222, 222]], dtype=int32),\n",
       " array([[ 15,  80, 233, 233]], dtype=int32),\n",
       " array([[ 18,  84, 230, 230]], dtype=int32),\n",
       " array([[ 19,  86, 223, 223]], dtype=int32),\n",
       " array([[ 23,  95, 214, 214]], dtype=int32),\n",
       " array([[  9,  80, 239, 239]], dtype=int32),\n",
       " array([[ 22,  88, 217, 217]], dtype=int32),\n",
       " array([[ 27,  92, 216, 216]], dtype=int32),\n",
       " array([[ 25,  95, 214, 214]], dtype=int32),\n",
       " array([[ 28,  91, 210, 210]], dtype=int32),\n",
       " array([[ 21,  88, 220, 220]], dtype=int32),\n",
       " array([[ 26,  94, 210, 210]], dtype=int32),\n",
       " array([[ 26,  89, 216, 216]], dtype=int32),\n",
       " array([[ 21,  85, 223, 223]], dtype=int32),\n",
       " array([[ 25,  89, 222, 222]], dtype=int32),\n",
       " array([[ 33,  95, 203, 203]], dtype=int32),\n",
       " array([[ 32,  97, 210, 210]], dtype=int32),\n",
       " array([[ 15,  91, 230, 230]], dtype=int32),\n",
       " array([[ 18,  91, 233, 233]], dtype=int32),\n",
       " array([[ 25,  84, 219, 219]], dtype=int32),\n",
       " array([[ 23,  87, 221, 221]], dtype=int32),\n",
       " array([[ 15,  81, 230, 230]], dtype=int32),\n",
       " array([[ 16,  75, 234, 234]], dtype=int32),\n",
       " array([[ 23,  89, 219, 219]], dtype=int32),\n",
       " array([[ 24,  92, 218, 218]], dtype=int32),\n",
       " array([[ 16,  82, 230, 230]], dtype=int32),\n",
       " array([[ 17,  82, 226, 226]], dtype=int32),\n",
       " array([[ 21,  83, 225, 225]], dtype=int32),\n",
       " array([[ 28,  93, 214, 214]], dtype=int32),\n",
       " array([[ 21,  87, 224, 224]], dtype=int32),\n",
       " array([[ 26,  92, 218, 218]], dtype=int32),\n",
       " array([[ 20,  86, 225, 225]], dtype=int32),\n",
       " array([[ 19,  86, 228, 228]], dtype=int32),\n",
       " array([[ 21,  88, 223, 223]], dtype=int32),\n",
       " array([[ 22,  85, 222, 222]], dtype=int32),\n",
       " array([[ 23,  86, 221, 221]], dtype=int32),\n",
       " array([[ 21,  86, 222, 222]], dtype=int32),\n",
       " array([[ 19,  85, 231, 231]], dtype=int32),\n",
       " array([[ 21,  90, 223, 223]], dtype=int32),\n",
       " array([[ 25,  86, 217, 217]], dtype=int32),\n",
       " array([[ 12,  82, 234, 234]], dtype=int32),\n",
       " array([[ 37,  94, 203, 203]], dtype=int32),\n",
       " array([[ 17,  80, 233, 233]], dtype=int32),\n",
       " array([[ 29,  89, 212, 212]], dtype=int32),\n",
       " array([[ 16,  82, 230, 230]], dtype=int32),\n",
       " array([[ 16,  81, 234, 234]], dtype=int32),\n",
       " array([[ 29,  91, 212, 212]], dtype=int32),\n",
       " array([[ 29,  92, 211, 211]], dtype=int32),\n",
       " array([[ 19,  83, 227, 227]], dtype=int32),\n",
       " array([[ 23,  88, 215, 215]], dtype=int32),\n",
       " array([[ 26,  93, 215, 215]], dtype=int32),\n",
       " array([[ 32,  87, 214, 214]], dtype=int32),\n",
       " array([[ 19,  85, 225, 225]], dtype=int32),\n",
       " array([[ 19,  87, 223, 223]], dtype=int32),\n",
       " array([[ 26,  90, 217, 217]], dtype=int32),\n",
       " array([[ 18,  84, 229, 229]], dtype=int32),\n",
       " array([[ 17,  76, 230, 230]], dtype=int32),\n",
       " array([[ 22,  94, 222, 222]], dtype=int32),\n",
       " array([[ 34,  97, 203, 203]], dtype=int32),\n",
       " array([[ 17,  84, 228, 228]], dtype=int32),\n",
       " array([[ 28,  87, 211, 211]], dtype=int32),\n",
       " array([[ 27,  90, 215, 215]], dtype=int32),\n",
       " array([[ 32,  98, 205, 205]], dtype=int32),\n",
       " array([[ 21,  84, 222, 222]], dtype=int32),\n",
       " array([[ 12,  87, 241, 241]], dtype=int32),\n",
       " array([[ 29,  90, 211, 211]], dtype=int32),\n",
       " array([[ 22,  83, 222, 222]], dtype=int32),\n",
       " array([[ 28,  89, 209, 209]], dtype=int32),\n",
       " array([[ 28,  92, 212, 212]], dtype=int32),\n",
       " array([[ 10,  72, 242, 242]], dtype=int32),\n",
       " array([[ 22,  85, 226, 226]], dtype=int32),\n",
       " array([[ 17,  86, 225, 225]], dtype=int32),\n",
       " array([[ 25,  89, 216, 216]], dtype=int32),\n",
       " array([[ 24,  88, 216, 216]], dtype=int32),\n",
       " array([[ 21,  83, 224, 224]], dtype=int32),\n",
       " array([[ 20,  87, 221, 221]], dtype=int32),\n",
       " array([[ 23,  91, 221, 221]], dtype=int32),\n",
       " array([[ 26,  86, 216, 216]], dtype=int32),\n",
       " array([[ 22,  92, 227, 227]], dtype=int32),\n",
       " array([[ 18,  83, 225, 225]], dtype=int32),\n",
       " array([[ 18,  84, 225, 225]], dtype=int32),\n",
       " array([[ 27,  93, 214, 214]], dtype=int32),\n",
       " array([[ 25,  89, 213, 213]], dtype=int32),\n",
       " array([[ 27,  84, 218, 218]], dtype=int32),\n",
       " array([[ 26,  88, 218, 218]], dtype=int32),\n",
       " array([[ 26,  86, 215, 215]], dtype=int32),\n",
       " array([[ 20,  90, 221, 221]], dtype=int32),\n",
       " array([[ 36,  96, 200, 200]], dtype=int32),\n",
       " array([[ 28,  87, 215, 215]], dtype=int32),\n",
       " array([[ 19,  85, 228, 228]], dtype=int32),\n",
       " array([[ 22,  85, 222, 222]], dtype=int32),\n",
       " array([[ 26,  91, 217, 217]], dtype=int32),\n",
       " array([[ 19,  83, 226, 226]], dtype=int32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# Detect faces in the image\n",
    "f_haar= [ face_cascade.detectMultiScale(\n",
    "    img,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    ") for img in f_grey]\n",
    "\n",
    "m_haar=[face_cascade.detectMultiScale(\n",
    "    img,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    ") for img in m_grey]\n",
    "m_haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 faces!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-acd8bd1e1c77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Draw a rectangle around the faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf_haar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mf_rec\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfemales\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mm_rec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmales\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# print haar affect\n",
    "print (\"Found {0} faces!\".format(len(f_haar)))\n",
    "\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in f_haar:\n",
    "    f_rec= [cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2) for img in females]\n",
    "    m_rec=[cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2) for img in males]\n",
    "\n",
    "        \n",
    "cv2.imshow(\"Faces found\", f_rec[0])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_alignment'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d94ad27e8377>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mface_alignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_alignment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFaceAlignment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_alignment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLandmarksType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflip_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#input = io.imread('../test/assets/aflw-test.jpg')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_alignment'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import face_alignment\n",
    "from skimage import io\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False)\n",
    "\n",
    "#input = io.imread('../test/assets/aflw-test.jpg')\n",
    "preds = fa.get_landmarks(m_haar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image using PIL module \n",
    "import sys, numpy as np, os \n",
    "# importing PIL \n",
    "from PIL import Image \n",
    "import glob\n",
    "  \n",
    "# Read image \n",
    "females2 = [Image.open(file) for file in glob.glob('C:\\\\Users\\\\MeaadAlrshoud\\\\Documents\\\\GitHub\\\\Gender-Classification\\\\Female_Dataset\\\\*.jpg')]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_data shape:', np.array(f_grey).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 27,  96, 211, 211]], dtype=int32), array([[ 28,  91, 212, 212]], dtype=int32), array([[ 31,  96, 206, 206]], dtype=int32), array([[ 22,  94, 220, 220]], dtype=int32), array([[ 27,  92, 216, 216]], dtype=int32), array([[ 25,  89, 219, 219]], dtype=int32), array([[ 27,  92, 220, 220]], dtype=int32), array([[ 28,  90, 211, 211]], dtype=int32), array([[ 37,  97, 200, 200]], dtype=int32), array([[ 27,  93, 212, 212]], dtype=int32), array([[ 28,  90, 213, 213]], dtype=int32), array([[ 23,  86, 224, 224]], dtype=int32), array([[ 22,  87, 220, 220]], dtype=int32), array([[ 21,  88, 219, 219]], dtype=int32), array([[ 25,  92, 217, 217]], dtype=int32), array([[ 24,  89, 216, 216]], dtype=int32), array([[ 24,  86, 220, 220]], dtype=int32), array([[ 30,  98, 204, 204]], dtype=int32), array([[ 28,  99, 210, 210]], dtype=int32), array([[ 28,  90, 211, 211]], dtype=int32), array([[ 28,  88, 214, 214]], dtype=int32), array([[ 29,  94, 209, 209]], dtype=int32), array([[ 31,  92, 204, 204]], dtype=int32), array([[ 23,  86, 221, 221]], dtype=int32), array([[ 27,  92, 213, 213]], dtype=int32), array([[ 32,  94, 205, 205]], dtype=int32), array([[ 28,  91, 209, 209]], dtype=int32), array([[ 35,  96, 200, 200]], dtype=int32), array([[ 15,  75, 236, 236]], dtype=int32), array([[ 32,  97, 209, 209]], dtype=int32), array([[ 30,  95, 210, 210]], dtype=int32), array([[ 28,  91, 215, 215]], dtype=int32), array([[ 32,  92, 208, 208]], dtype=int32), array([[ 30,  92, 205, 205]], dtype=int32), array([[ 28,  96, 210, 210]], dtype=int32), array([[ 27,  95, 216, 216]], dtype=int32), array([[ 30,  95, 211, 211]], dtype=int32), array([[ 19,  91, 227, 227]], dtype=int32), array([[ 24,  89, 220, 220]], dtype=int32), array([[ 30,  95, 208, 208]], dtype=int32), array([[ 26,  98, 217, 217]], dtype=int32), array([[ 30,  99, 208, 208]], dtype=int32), array([[ 30,  91, 207, 207]], dtype=int32), array([[ 29,  80, 213, 213]], dtype=int32), array([[ 26,  87, 218, 218]], dtype=int32), array([[ 27,  93, 212, 212]], dtype=int32), array([[ 26,  89, 213, 213]], dtype=int32), array([[ 27,  90, 216, 216]], dtype=int32), array([[ 20,  98, 220, 220]], dtype=int32), array([[ 24,  94, 215, 215]], dtype=int32), array([[ 28,  90, 215, 215]], dtype=int32), array([[ 17,  96, 231, 231]], dtype=int32), array([[ 35,  96, 200, 200]], dtype=int32), array([[ 27,  89, 216, 216]], dtype=int32), array([[ 29,  94, 209, 209]], dtype=int32), array([[ 18,  89, 227, 227]], dtype=int32), array([[ 26,  92, 212, 212]], dtype=int32), array([[ 17,  83, 231, 231]], dtype=int32), array([[ 31, 100, 206, 206]], dtype=int32), array([[ 22,  91, 220, 220]], dtype=int32), array([[ 24,  92, 217, 217]], dtype=int32), array([[ 21,  89, 225, 225]], dtype=int32), array([[ 16,  86, 237, 237]], dtype=int32), array([[ 29,  87, 215, 215]], dtype=int32), array([[ 25,  88, 216, 216]], dtype=int32), array([[ 15,  78, 231, 231]], dtype=int32), array([[ 28,  92, 211, 211]], dtype=int32), array([[ 22,  94, 225, 225]], dtype=int32), array([[ 22,  88, 224, 224]], dtype=int32), array([[ 25,  92, 215, 215]], dtype=int32), array([[ 25,  90, 216, 216]], dtype=int32), array([[ 18,  79, 226, 226]], dtype=int32), array([[ 22,  90, 220, 220]], dtype=int32), array([[ 28,  92, 215, 215]], dtype=int32), array([[ 22,  86, 217, 217]], dtype=int32), array([[ 30,  92, 211, 211]], dtype=int32), array([[ 26,  92, 217, 217]], dtype=int32), array([[ 21,  92, 227, 227]], dtype=int32), array([[ 28,  92, 213, 213]], dtype=int32), array([[ 32,  98, 204, 204]], dtype=int32), array([[ 27,  93, 212, 212]], dtype=int32), array([[ 25,  91, 215, 215]], dtype=int32), array([[ 24,  86, 218, 218]], dtype=int32), array([[ 39, 104, 196, 196]], dtype=int32), array([[ 22,  89, 220, 220]], dtype=int32), array([[ 31,  95, 211, 211]], dtype=int32), array([[ 27,  91, 213, 213]], dtype=int32), array([[ 22,  90, 222, 222]], dtype=int32), array([[ 23,  88, 218, 218]], dtype=int32), array([[ 28,  89, 213, 213]], dtype=int32), array([[ 27,  93, 209, 209]], dtype=int32), array([[ 19,  86, 225, 225]], dtype=int32), array([[ 36, 101, 199, 199]], dtype=int32), array([[ 34, 101, 201, 201]], dtype=int32), array([[ 30,  90, 214, 214]], dtype=int32), array([[ 26,  93, 214, 214]], dtype=int32), array([[ 24,  91, 219, 219]], dtype=int32), array([[ 29,  95, 208, 208]], dtype=int32), array([[ 31,  97, 210, 210]], dtype=int32)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=os.getcwd()\n",
    "femaleP='C:/Users/meaad/Desktop/Gender/Female_Dataset/*.jpg'\n",
    "X_data = []\n",
    "files = glob.glob (femaleP)\n",
    "for myFile in files:\n",
    "    image = cv2.imread (myFile)\n",
    "    if image is not None:\n",
    "        X_data.append(image)\n",
    "print('X_data shape:', np.array(X_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#Read Image\n",
    "img = cv2.imread('C:\\\\Users\\\\MeaadAlrshoud\\\\Documents\\\\GitHub\\\\Gender-Classification\\\\Female_Dataset\\\\11a.jpg')\n",
    "#Display Image\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Applying Grayscale filter to image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "im = np.float32(img) / 255.0\n",
    "\n",
    "# Calculate gradient \n",
    "gx = cv2.Sobel(im, cv2.CV_32F, 1, 0, ksize=1)\n",
    "gy = cv2.Sobel(im, cv2.CV_32F, 0, 1, ksize=1)\n",
    "\n",
    "mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "\n",
    "#Saving filtered image to new file\n",
    "cv2.imwrite('test3.jpg',im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image =mpimg.imread('C:\\\\Users\\\\MeaadAlrshoud\\\\Documents\\\\GitHub\\\\Gender-Classification\\\\Female_Dataset\\\\11a.jpg')\n",
    "\n",
    "\n",
    "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "for img in f_grey:\n",
    "    fd, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(img, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
